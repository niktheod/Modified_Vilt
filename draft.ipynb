{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import torchvision\n",
    "\n",
    "from PIL import Image\n",
    "from utility import ViltImageSetProcessor\n",
    "from transformers import ViltImageProcessor, BertTokenizer, ViTModel, ViTConfig, ViTImageProcessor\n",
    "from models import MultiviewViltForQuestionAnswering, MultiviewViltModel\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from isvqa_data_setup import ISVQA\n",
    "from torch.utils.data import DataLoader\n",
    "from engine import max_to_one_hot\n",
    "from collections import Counter\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "with open(\"/home/nikostheodoridis/nuscenes/v1.0-trainval/sample_data.json\") as f:\n",
    "    set = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n",
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vit_b_16-c867db91.pth\" to /home/nikostheodoridis/.cache/torch/hub/checkpoints/vit_b_16-c867db91.pth\n",
      "100%|██████████| 330M/330M [00:02<00:00, 116MB/s]  \n"
     ]
    }
   ],
   "source": [
    "weights = torchvision.models.ViT_B_16_Weights\n",
    "vit = torchvision.models.vit_b_16(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit2 = ViTModel(ViTConfig()).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit2 = ViTModel(ViTConfig())\n",
    "img = torch.randn((1, 3, 224, 224))\n",
    "\n",
    "out = vit2(img)\n",
    "my_pooler = torch.matmul(vit2.pooler.dense.weight, out[0][:, 0].T).T + vit2.pooler.dense.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[-1.9228, -0.0363, -1.3237,  ...,  0.6033,  0.4010, -0.2963],\n",
       "         [ 0.2995,  0.2434, -0.3559,  ...,  1.2787, -0.2542, -1.2179],\n",
       "         [ 0.1287,  0.5816, -0.2105,  ..., -0.1496,  0.2117, -0.6212],\n",
       "         ...,\n",
       "         [-2.0719,  0.7310,  0.1939,  ...,  1.0240,  1.2290,  0.9660],\n",
       "         [ 0.6128, -0.6037, -0.4326,  ...,  0.3306, -1.2665,  0.9593],\n",
       "         [-1.5866,  0.2553,  0.0570,  ...,  0.3944, -0.8897,  1.5030]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-1.2910e-01,  4.7080e-01, -2.3381e-01, -1.7056e-01,  4.1828e-01,\n",
       "          1.3459e-01,  5.4096e-01,  7.7265e-01,  6.4455e-01,  1.5180e-01,\n",
       "          1.5184e-01, -2.4485e-01,  3.9936e-01,  2.3162e-01,  3.9372e-01,\n",
       "          7.9987e-02,  2.7627e-01,  6.1587e-01, -2.1772e-01,  3.6806e-01,\n",
       "         -5.2010e-01, -7.8098e-01,  3.4164e-01,  4.2666e-01, -7.6649e-01,\n",
       "         -2.7599e-01,  7.1899e-01, -4.6672e-01, -6.8824e-01,  3.1623e-01,\n",
       "          7.2091e-01,  3.6000e-01,  3.8967e-01, -9.0043e-01, -2.6182e-01,\n",
       "         -4.8506e-01,  9.2396e-01,  5.4459e-01,  2.5431e-01, -2.6105e-01,\n",
       "         -3.4168e-02, -3.8132e-01, -4.4980e-01,  6.1377e-01,  8.7427e-01,\n",
       "         -3.5903e-01,  8.1502e-01, -3.1421e-02, -4.5776e-01,  4.6302e-02,\n",
       "         -1.4488e-02,  2.6111e-01,  6.8523e-01, -3.2932e-01, -3.1614e-01,\n",
       "         -6.0470e-01,  3.3982e-01,  5.8282e-01,  7.7981e-02, -4.9320e-01,\n",
       "         -4.4226e-02,  5.2257e-01, -2.5026e-01, -2.8347e-01,  5.2039e-02,\n",
       "         -2.9842e-01,  2.9126e-01,  2.1774e-01,  8.5991e-01,  2.1232e-02,\n",
       "         -5.6556e-01, -2.9453e-01,  8.5944e-01,  6.4954e-01,  3.9048e-01,\n",
       "          8.7490e-01,  1.2270e-01,  5.0312e-01, -3.3460e-01,  2.8160e-01,\n",
       "         -2.1273e-01, -6.9883e-01, -6.3882e-01, -6.4778e-01,  4.5141e-01,\n",
       "          1.4506e-01,  1.9576e-01,  6.7968e-01, -7.0969e-01, -4.1024e-01,\n",
       "         -1.8414e-01,  8.5023e-01,  3.0901e-01, -5.3726e-01, -1.0122e-01,\n",
       "         -7.6301e-01,  1.8845e-01, -8.5188e-01,  5.2172e-01, -3.2990e-01,\n",
       "          5.2572e-01,  6.8838e-01,  3.4844e-01,  4.2947e-01, -1.3047e-01,\n",
       "          3.3652e-01,  6.2496e-01,  1.3402e-01, -5.4114e-01, -6.4192e-01,\n",
       "          3.2358e-01, -7.2410e-01, -6.9330e-01,  5.0701e-01,  7.5889e-01,\n",
       "         -1.8669e-02, -3.0387e-01, -2.0217e-01, -5.3591e-01, -7.2288e-02,\n",
       "          5.5034e-01,  2.5220e-01, -4.1666e-02,  2.5712e-01,  1.4728e-01,\n",
       "          1.3063e-01,  2.4011e-01, -5.1502e-01, -7.1560e-01,  3.6613e-01,\n",
       "          6.3450e-01, -3.2099e-01, -5.1156e-01,  8.7713e-01, -5.6614e-01,\n",
       "          6.9753e-01,  8.2797e-02, -2.6580e-01, -5.9470e-02,  8.2455e-01,\n",
       "          6.9059e-02, -1.0784e-01,  4.6468e-01, -1.8646e-01, -6.3636e-01,\n",
       "         -2.9220e-01, -6.9641e-01,  4.2531e-01,  7.9920e-02, -3.8345e-01,\n",
       "         -6.4082e-01, -3.1753e-02, -4.4607e-01,  2.1814e-01,  1.9879e-02,\n",
       "          4.4812e-01, -8.3055e-01, -6.7304e-01,  8.4667e-01,  7.2178e-01,\n",
       "          4.2967e-01,  5.4107e-01,  3.4960e-01,  5.2153e-01,  3.6236e-01,\n",
       "          5.3343e-01,  1.1323e-01,  7.4424e-01, -4.1899e-01, -4.5741e-01,\n",
       "          1.9572e-01,  3.8343e-01,  4.3989e-01, -1.4477e-01, -6.2036e-01,\n",
       "          7.3050e-01,  7.3398e-01,  3.2484e-01, -9.3359e-01,  4.0743e-01,\n",
       "         -1.6275e-01, -1.8820e-01, -5.6228e-01, -4.2184e-01, -3.1944e-01,\n",
       "          6.6063e-01, -2.4476e-01, -1.3991e-02,  2.6080e-01,  3.6465e-01,\n",
       "          6.4727e-01, -4.5208e-01,  7.9712e-01,  4.0470e-01, -5.7532e-01,\n",
       "         -4.6533e-02, -2.6430e-01, -2.2061e-01, -5.1391e-01, -7.5981e-01,\n",
       "          5.3640e-01, -1.1952e-01, -7.5427e-01, -3.9476e-01, -9.7060e-02,\n",
       "         -1.4109e-01, -7.6558e-01,  2.5107e-01,  7.5156e-01, -7.8622e-01,\n",
       "          4.5135e-01,  7.5319e-02, -7.4099e-01, -8.9555e-02, -4.9455e-01,\n",
       "          4.4757e-01, -8.7779e-01, -6.2143e-01,  5.4635e-01,  6.5760e-02,\n",
       "         -2.3186e-01, -6.9296e-01, -2.4341e-01, -8.3367e-01, -5.2439e-01,\n",
       "         -8.4025e-01,  5.7943e-01, -1.0838e-01,  3.4386e-01,  1.0655e-01,\n",
       "          2.7073e-01,  6.4374e-02,  5.9598e-01, -2.0132e-01, -7.8290e-01,\n",
       "          4.9503e-01, -2.5492e-01, -5.2682e-01,  1.4952e-01, -6.4568e-01,\n",
       "         -3.1559e-01, -3.6300e-01,  3.3353e-02, -1.0461e-01,  2.4000e-01,\n",
       "         -8.3358e-01,  3.3744e-01, -3.2940e-01, -3.4065e-01, -3.5438e-01,\n",
       "          4.1198e-01,  1.1531e-01,  3.1631e-01,  3.0591e-01, -8.0095e-01,\n",
       "          4.8103e-01,  5.4693e-01, -2.4438e-01,  4.3041e-01, -6.7104e-01,\n",
       "          2.0723e-01,  6.1649e-01,  3.2827e-01,  6.2554e-01,  1.6157e-01,\n",
       "         -1.9165e-01,  8.2550e-01,  4.9467e-01, -2.2872e-01, -2.0652e-01,\n",
       "          4.2103e-01,  4.8207e-02,  1.9725e-01,  5.3005e-01,  2.1288e-01,\n",
       "         -5.1554e-01, -8.8741e-01, -3.5142e-01,  5.6877e-02, -3.7119e-01,\n",
       "         -8.9827e-01, -3.4347e-01,  7.8569e-01, -9.3199e-02, -1.8476e-02,\n",
       "         -4.0930e-01, -2.0684e-01,  2.7545e-01,  7.4111e-01,  1.2596e-01,\n",
       "          4.4149e-01,  2.3331e-01,  3.7830e-02,  1.2610e-01,  1.3269e-01,\n",
       "          3.7084e-01,  6.4192e-01,  7.7832e-01, -1.4248e-01, -1.4320e-01,\n",
       "         -3.2222e-02,  3.1972e-01,  1.7881e-01, -5.2888e-01,  1.4615e-01,\n",
       "         -2.0096e-01, -4.0732e-01, -7.7302e-01, -8.1428e-01, -4.7015e-01,\n",
       "          8.3621e-01, -1.9668e-01,  7.4818e-01, -5.9922e-01, -2.5085e-01,\n",
       "          6.5441e-01, -3.9715e-01, -2.2862e-01,  6.3567e-01, -4.2508e-01,\n",
       "          6.8099e-01, -6.2691e-01,  2.7153e-01,  1.9705e-01,  1.3481e-01,\n",
       "          3.4510e-01,  5.1098e-02, -7.4408e-01, -6.1034e-01, -4.0322e-01,\n",
       "          1.8987e-01,  6.3391e-01,  2.7359e-01,  1.5548e-01, -7.4755e-01,\n",
       "         -4.9881e-01, -3.8005e-01,  6.7778e-01, -8.6211e-01,  1.0788e-01,\n",
       "         -8.8877e-02, -4.5903e-01, -7.0055e-01, -4.1481e-01,  8.7233e-01,\n",
       "          6.0927e-02,  5.1469e-03,  1.2844e-01, -1.8476e-01,  3.7265e-01,\n",
       "         -3.8341e-01,  2.7849e-01,  1.7085e-01, -7.2460e-01, -2.8547e-01,\n",
       "         -8.6266e-01,  7.3672e-01, -2.9903e-01,  4.1151e-01, -6.4992e-01,\n",
       "          3.6230e-01, -6.0348e-02, -1.6523e-01,  3.3073e-01,  7.7556e-02,\n",
       "          2.3470e-01, -2.0029e-01,  7.8971e-01, -1.2879e-02,  3.5406e-02,\n",
       "         -9.8818e-02, -1.0778e-02,  4.7804e-01,  5.1158e-01,  2.7521e-02,\n",
       "         -4.0975e-02, -1.7196e-01, -2.8785e-01, -6.3590e-01, -6.8848e-01,\n",
       "          5.2520e-02, -2.1205e-01,  1.3301e-01, -5.0093e-02, -2.5197e-02,\n",
       "         -8.5173e-02,  1.6602e-01, -6.0612e-01, -7.0417e-01,  9.7619e-02,\n",
       "         -3.7054e-01,  1.2600e-01,  2.8564e-01, -3.9151e-01, -1.3871e-01,\n",
       "         -6.2481e-01,  3.6030e-02, -4.2078e-01, -1.4107e-01,  7.7053e-01,\n",
       "         -7.7925e-01, -5.8675e-01, -3.2545e-01,  1.3388e-01,  1.5054e-01,\n",
       "          4.8925e-01, -3.9980e-01, -3.0792e-01, -7.1292e-02, -4.5676e-01,\n",
       "         -8.1615e-01, -4.5328e-01,  4.0402e-01, -8.4800e-01,  5.1700e-01,\n",
       "         -1.5025e-01, -4.6125e-01, -2.2300e-02,  7.6852e-02,  2.2153e-01,\n",
       "          2.6535e-01, -3.1935e-01, -5.6311e-01, -9.0735e-01, -3.6784e-01,\n",
       "          4.3479e-02,  5.9822e-01, -5.9374e-01,  1.9497e-01, -1.2071e-03,\n",
       "          3.6205e-01,  6.5663e-01,  4.4018e-01,  3.9092e-01, -6.3649e-02,\n",
       "         -2.2873e-01, -9.5137e-01, -2.4681e-01,  4.6834e-01, -1.7092e-01,\n",
       "         -3.5404e-01,  1.8563e-01,  2.1238e-01,  2.5798e-01,  7.7494e-01,\n",
       "          1.9894e-01, -2.0823e-01, -7.3702e-01, -2.4188e-01,  3.9484e-01,\n",
       "         -1.2167e-01, -2.1883e-01,  3.1623e-01, -1.7976e-01,  3.0620e-01,\n",
       "          4.5939e-03,  2.5037e-01, -2.3786e-01,  4.7561e-01, -2.2100e-01,\n",
       "          3.6126e-01,  6.5042e-01, -1.8671e-02,  2.5883e-01, -2.8901e-01,\n",
       "          5.3961e-01, -2.7321e-01, -5.4811e-01, -4.0872e-01, -1.7240e-01,\n",
       "         -4.9965e-01, -4.8401e-02,  1.1459e-01,  1.3179e-01,  4.8601e-01,\n",
       "          2.9438e-02, -3.3905e-02,  4.0006e-01, -9.4346e-02,  4.2769e-01,\n",
       "          1.3901e-02,  8.0697e-01, -4.3574e-01, -1.8349e-01, -2.0673e-01,\n",
       "          7.6875e-01,  7.1169e-01, -1.4365e-02,  7.3901e-02, -6.8893e-01,\n",
       "          3.5168e-01,  2.5635e-01, -4.8097e-01,  6.2709e-01, -5.1787e-01,\n",
       "          6.1134e-01,  1.7066e-01,  2.6097e-01,  7.3555e-01, -4.3269e-01,\n",
       "         -7.0386e-01,  8.2014e-02, -4.6303e-01,  3.2487e-01,  4.4817e-01,\n",
       "          5.8725e-01, -8.3665e-01,  6.2506e-01, -2.5563e-01, -2.4101e-01,\n",
       "         -7.2239e-02,  4.5364e-01, -7.7516e-01,  7.4330e-01, -1.2452e-01,\n",
       "          5.8103e-01,  3.7633e-02, -1.5914e-01,  2.8203e-01, -4.1208e-03,\n",
       "          4.4188e-02,  5.9712e-01, -9.0420e-02,  6.5297e-01, -7.7282e-01,\n",
       "         -1.4344e-01,  4.1743e-01,  2.4746e-01, -4.9490e-01, -7.1579e-03,\n",
       "          1.3290e-01, -2.9123e-01,  4.3927e-01,  2.4548e-01,  2.4413e-01,\n",
       "          3.4584e-01, -2.0490e-01,  2.4366e-01, -5.3756e-01,  3.0862e-01,\n",
       "         -1.0841e-01,  8.5338e-01,  4.1551e-01,  4.4041e-02, -1.6084e-01,\n",
       "          4.4946e-01, -4.7297e-01, -1.9974e-01, -2.2061e-01,  3.7576e-01,\n",
       "         -1.0873e-01, -2.6890e-01, -5.1924e-01, -5.5200e-01,  9.8131e-03,\n",
       "          1.7200e-01, -7.3123e-02, -8.5854e-01,  3.1208e-01, -6.5157e-01,\n",
       "          1.0477e-01, -2.3962e-01, -4.9533e-02,  5.5466e-01, -1.9573e-01,\n",
       "         -4.3298e-01, -5.5686e-01, -5.4681e-01,  2.5414e-01,  2.6328e-02,\n",
       "         -5.2559e-01, -1.6689e-01,  8.0614e-01,  4.5261e-01, -1.8314e-01,\n",
       "         -6.9800e-01,  1.5926e-01,  7.7806e-01, -6.1947e-01,  2.3835e-01,\n",
       "          3.7725e-02, -6.5068e-01,  3.8022e-01, -5.6665e-01, -6.1248e-01,\n",
       "          5.1222e-01, -2.4344e-01,  2.0868e-01, -7.4138e-01, -8.0538e-01,\n",
       "         -2.6648e-01, -4.8967e-01,  2.3669e-01, -6.5841e-01, -5.9799e-01,\n",
       "          8.2956e-01, -3.6587e-01,  2.7274e-01,  4.1482e-01,  5.1724e-01,\n",
       "         -3.3635e-03,  4.3683e-02,  6.1359e-01, -2.5995e-02,  7.5728e-01,\n",
       "          5.3555e-01, -3.4063e-01,  9.6396e-02,  4.1966e-01, -4.3665e-01,\n",
       "          6.3483e-01, -4.6711e-01, -4.3901e-01, -7.8256e-01, -3.8259e-01,\n",
       "         -8.9211e-01,  2.6968e-01,  7.4783e-01, -7.3296e-01, -1.7747e-01,\n",
       "         -5.7992e-02, -6.1241e-01, -4.5911e-01,  2.5677e-01,  4.0485e-01,\n",
       "          1.5782e-01, -5.1339e-01, -1.1117e-01, -5.4280e-01, -5.5586e-01,\n",
       "         -1.0150e-01,  3.1570e-01, -1.6571e-01, -5.5082e-04, -7.1881e-01,\n",
       "         -2.5987e-01, -7.2280e-01,  6.7509e-01, -1.7998e-02, -3.3388e-01,\n",
       "          7.0992e-02,  4.0874e-01, -7.0464e-01, -4.6595e-01,  7.6829e-01,\n",
       "         -1.2506e-01, -2.7212e-01,  6.3926e-01, -3.3316e-01, -6.9424e-01,\n",
       "         -5.0301e-01, -3.1188e-01, -6.0642e-01,  8.6407e-01,  2.1139e-01,\n",
       "         -1.8614e-03,  3.2848e-01,  3.2796e-01,  4.2956e-01,  8.2022e-01,\n",
       "          3.1118e-01, -6.4361e-01, -1.8190e-01,  1.5036e-01, -7.5966e-02,\n",
       "          4.0151e-01,  5.4001e-01, -6.7448e-01, -5.4053e-01, -7.0732e-01,\n",
       "         -2.4855e-01,  6.5447e-01, -5.5621e-01, -1.5030e-01, -1.5315e-01,\n",
       "          2.0090e-01, -3.1824e-01, -2.7647e-01,  4.2274e-01, -9.4838e-02,\n",
       "         -7.8448e-02, -8.2595e-01, -9.8527e-02,  1.4366e-01, -3.4016e-02,\n",
       "          6.1824e-01, -7.8144e-02, -3.4152e-01, -1.2899e-01,  2.9029e-01,\n",
       "          1.1980e-01, -3.5246e-01,  1.8043e-01, -2.7998e-01, -4.8702e-01,\n",
       "          2.6181e-01,  2.7607e-01, -6.6190e-01,  3.6182e-01, -5.9707e-02,\n",
       "         -4.8674e-01,  5.5613e-01,  1.8356e-01,  1.7706e-01, -2.0100e-02,\n",
       "          2.4150e-01, -6.0308e-01, -6.6542e-01, -3.1487e-01, -5.7875e-01,\n",
       "         -2.9411e-01, -5.7656e-01,  4.7186e-01,  2.4413e-01,  3.4872e-01,\n",
       "         -8.6439e-02, -4.2463e-01,  4.9388e-01, -1.0585e-02,  3.3521e-01,\n",
       "         -2.9849e-01, -7.2309e-01,  2.5460e-01, -3.6332e-01, -5.4502e-01,\n",
       "          5.4955e-01,  2.1079e-01, -1.8061e-01, -3.5886e-01, -5.7860e-01,\n",
       "          3.8249e-01,  1.3172e-01, -5.7458e-01, -6.6151e-01,  4.5388e-01,\n",
       "         -1.9102e-01,  1.8725e-01, -4.0514e-01,  6.9566e-02, -4.4240e-02,\n",
       "         -6.5234e-01, -8.9874e-01, -5.4393e-01, -1.4988e-01, -5.2828e-01,\n",
       "          3.0110e-01, -2.9829e-01,  4.1544e-01,  1.6246e-01,  6.8215e-01,\n",
       "          2.3957e-01,  6.6131e-01,  2.6123e-01,  6.5835e-01,  5.4412e-01,\n",
       "          4.9304e-01, -2.6413e-01, -6.1961e-01, -5.2834e-01, -5.3541e-01,\n",
       "          6.7180e-01,  4.4788e-01, -7.9710e-02,  2.6361e-01,  5.5753e-02,\n",
       "         -1.7283e-01, -5.9948e-01, -4.4581e-01]], grad_fn=<TanhBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[1].shape, out[0][:, 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pooler = torch.matmul(vit2.pooler.dense.weight, out[0][:, 0].T).T + vit2.pooler.dense.bias\n",
    "\n",
    "tanh = nn.Tanh()\n",
    "\n",
    "my_pooler = tanh(my_pooler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pooler.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.equal(my_pooler, out[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTModel(\n",
      "  (embeddings): ViTEmbeddings(\n",
      "    (patch_embeddings): ViTPatchEmbeddings(\n",
      "      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): ViTEncoder(\n",
      "    (layer): ModuleList(\n",
      "      (0-11): 12 x ViTLayer(\n",
      "        (attention): ViTAttention(\n",
      "          (attention): ViTSelfAttention(\n",
      "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (output): ViTSelfOutput(\n",
      "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (intermediate): ViTIntermediate(\n",
      "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "        )\n",
      "        (output): ViTOutput(\n",
      "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "  (pooler): ViTPooler(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (activation): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vit2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = ViTImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"/home/nikostheodoridis/nuscenes/samples/CAM_BACK/n008-2018-05-21-11-06-59-0400__CAM_BACK__1526915243037570.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_img = transforms.ToTensor()(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor(tensor_img, do_rescale=False, return_tensors=\"pt\")[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Modules</th>\n",
       "            <th>Parameters</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>embeddings.word_embeddings.weight</td>\n",
       "            <td>23440896</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>embeddings.position_embeddings.weight</td>\n",
       "            <td>393216</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>embeddings.token_type_embeddings.weight</td>\n",
       "            <td>1536</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>embeddings.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>embeddings.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.0.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.1.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.2.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.3.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.4.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.5.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.6.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.7.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.8.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.9.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.10.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.query.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.query.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.key.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.key.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.value.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.self.value.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.output.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.attention.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.intermediate.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.intermediate.dense.bias</td>\n",
       "            <td>3072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.output.dense.weight</td>\n",
       "            <td>2359296</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.output.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.output.LayerNorm.weight</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>encoder.layer.11.output.LayerNorm.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>pooler.dense.weight</td>\n",
       "            <td>589824</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>pooler.dense.bias</td>\n",
       "            <td>768</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>Total</td>\n",
       "            <td>109482240</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------------------------------------+------------+\n",
       "|                      Modules                       | Parameters |\n",
       "+----------------------------------------------------+------------+\n",
       "|         embeddings.word_embeddings.weight          |  23440896  |\n",
       "|       embeddings.position_embeddings.weight        |   393216   |\n",
       "|      embeddings.token_type_embeddings.weight       |    1536    |\n",
       "|            embeddings.LayerNorm.weight             |    768     |\n",
       "|             embeddings.LayerNorm.bias              |    768     |\n",
       "|    encoder.layer.0.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.0.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.0.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.0.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.0.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.0.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.0.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.0.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.0.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.0.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.0.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.0.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.0.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.0.output.dense.bias          |    768     |\n",
       "|      encoder.layer.0.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.0.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.1.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.1.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.1.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.1.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.1.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.1.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.1.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.1.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.1.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.1.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.1.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.1.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.1.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.1.output.dense.bias          |    768     |\n",
       "|      encoder.layer.1.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.1.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.2.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.2.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.2.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.2.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.2.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.2.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.2.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.2.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.2.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.2.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.2.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.2.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.2.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.2.output.dense.bias          |    768     |\n",
       "|      encoder.layer.2.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.2.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.3.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.3.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.3.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.3.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.3.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.3.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.3.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.3.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.3.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.3.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.3.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.3.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.3.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.3.output.dense.bias          |    768     |\n",
       "|      encoder.layer.3.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.3.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.4.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.4.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.4.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.4.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.4.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.4.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.4.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.4.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.4.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.4.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.4.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.4.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.4.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.4.output.dense.bias          |    768     |\n",
       "|      encoder.layer.4.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.4.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.5.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.5.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.5.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.5.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.5.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.5.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.5.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.5.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.5.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.5.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.5.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.5.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.5.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.5.output.dense.bias          |    768     |\n",
       "|      encoder.layer.5.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.5.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.6.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.6.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.6.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.6.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.6.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.6.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.6.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.6.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.6.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.6.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.6.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.6.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.6.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.6.output.dense.bias          |    768     |\n",
       "|      encoder.layer.6.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.6.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.7.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.7.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.7.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.7.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.7.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.7.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.7.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.7.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.7.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.7.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.7.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.7.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.7.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.7.output.dense.bias          |    768     |\n",
       "|      encoder.layer.7.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.7.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.8.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.8.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.8.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.8.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.8.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.8.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.8.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.8.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.8.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.8.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.8.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.8.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.8.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.8.output.dense.bias          |    768     |\n",
       "|      encoder.layer.8.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.8.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.9.attention.self.query.weight     |   589824   |\n",
       "|     encoder.layer.9.attention.self.query.bias      |    768     |\n",
       "|     encoder.layer.9.attention.self.key.weight      |   589824   |\n",
       "|      encoder.layer.9.attention.self.key.bias       |    768     |\n",
       "|    encoder.layer.9.attention.self.value.weight     |   589824   |\n",
       "|     encoder.layer.9.attention.self.value.bias      |    768     |\n",
       "|   encoder.layer.9.attention.output.dense.weight    |   589824   |\n",
       "|    encoder.layer.9.attention.output.dense.bias     |    768     |\n",
       "| encoder.layer.9.attention.output.LayerNorm.weight  |    768     |\n",
       "|  encoder.layer.9.attention.output.LayerNorm.bias   |    768     |\n",
       "|     encoder.layer.9.intermediate.dense.weight      |  2359296   |\n",
       "|      encoder.layer.9.intermediate.dense.bias       |    3072    |\n",
       "|        encoder.layer.9.output.dense.weight         |  2359296   |\n",
       "|         encoder.layer.9.output.dense.bias          |    768     |\n",
       "|      encoder.layer.9.output.LayerNorm.weight       |    768     |\n",
       "|       encoder.layer.9.output.LayerNorm.bias        |    768     |\n",
       "|    encoder.layer.10.attention.self.query.weight    |   589824   |\n",
       "|     encoder.layer.10.attention.self.query.bias     |    768     |\n",
       "|     encoder.layer.10.attention.self.key.weight     |   589824   |\n",
       "|      encoder.layer.10.attention.self.key.bias      |    768     |\n",
       "|    encoder.layer.10.attention.self.value.weight    |   589824   |\n",
       "|     encoder.layer.10.attention.self.value.bias     |    768     |\n",
       "|   encoder.layer.10.attention.output.dense.weight   |   589824   |\n",
       "|    encoder.layer.10.attention.output.dense.bias    |    768     |\n",
       "| encoder.layer.10.attention.output.LayerNorm.weight |    768     |\n",
       "|  encoder.layer.10.attention.output.LayerNorm.bias  |    768     |\n",
       "|     encoder.layer.10.intermediate.dense.weight     |  2359296   |\n",
       "|      encoder.layer.10.intermediate.dense.bias      |    3072    |\n",
       "|        encoder.layer.10.output.dense.weight        |  2359296   |\n",
       "|         encoder.layer.10.output.dense.bias         |    768     |\n",
       "|      encoder.layer.10.output.LayerNorm.weight      |    768     |\n",
       "|       encoder.layer.10.output.LayerNorm.bias       |    768     |\n",
       "|    encoder.layer.11.attention.self.query.weight    |   589824   |\n",
       "|     encoder.layer.11.attention.self.query.bias     |    768     |\n",
       "|     encoder.layer.11.attention.self.key.weight     |   589824   |\n",
       "|      encoder.layer.11.attention.self.key.bias      |    768     |\n",
       "|    encoder.layer.11.attention.self.value.weight    |   589824   |\n",
       "|     encoder.layer.11.attention.self.value.bias     |    768     |\n",
       "|   encoder.layer.11.attention.output.dense.weight   |   589824   |\n",
       "|    encoder.layer.11.attention.output.dense.bias    |    768     |\n",
       "| encoder.layer.11.attention.output.LayerNorm.weight |    768     |\n",
       "|  encoder.layer.11.attention.output.LayerNorm.bias  |    768     |\n",
       "|     encoder.layer.11.intermediate.dense.weight     |  2359296   |\n",
       "|      encoder.layer.11.intermediate.dense.bias      |    3072    |\n",
       "|        encoder.layer.11.output.dense.weight        |  2359296   |\n",
       "|         encoder.layer.11.output.dense.bias         |    768     |\n",
       "|      encoder.layer.11.output.LayerNorm.weight      |    768     |\n",
       "|       encoder.layer.11.output.LayerNorm.bias       |    768     |\n",
       "|                pooler.dense.weight                 |   589824   |\n",
       "|                 pooler.dense.bias                  |    768     |\n",
       "|                       Total                        | 109482240  |\n",
       "+----------------------------------------------------+------------+"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "scheduler_type = None\n",
    "\n",
    "\n",
    "if scheduler_type == \"steplr\":\n",
    "        print(1)\n",
    "elif scheduler_type is not None:\n",
    "    print(2)\n",
    "else:\n",
    "    print(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = StepLR(optimizer=optimizer, step_size=None, gamma=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 3, 352, 608])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isvqa[0][0][\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "isvqa = ISVQA(\"/home/nikostheodoridis/isvqa/train_set.json\",\n",
    "              \"/home/nikostheodoridis/nuscenes/samples\",\n",
    "              \"/home/nikostheodoridis/isvqa/answers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MultiviewViltForQuestionAnswering(6, 210, 40, 768, True, True, True).to(\"cpu\")\n",
    "layer = nn.TransformerEncoderLayer(768, 12, batch_first=True, dim_feedforward=3072)\n",
    "# model = nn.TransformerEncoder(layer, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "    table.add_row([\"Total\", total_params])\n",
    "    return table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(isvqa, 4, shuffle=False)\n",
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[ -9.9990, -11.7384,  -7.4223,  ...,  -9.9704, -11.2511, -10.7394],\n",
       "        [ -9.6335, -11.7417,  -7.1838,  ..., -10.0912, -11.4883, -10.6841],\n",
       "        [ -9.4269, -10.0896,  -7.3474,  ..., -11.3587, -12.3218,  -9.9821],\n",
       "        [ -9.4646, -10.1867,  -7.3609,  ..., -11.3594, -12.3701, -10.1991]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = torch.randn(4, 1, 768)\n",
    "images = torch.randn(4, 6, 768)\n",
    "\n",
    "attn_scores = torch.randn(4, 1, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.randn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_model_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params += param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(isvqa, 1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(**batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'torch.Size' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'torch.Size' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "out.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.TransformerEncoderLayer(768, 12, batch_first=True, dim_feedforward=3072)\n",
    "\n",
    "src = torch.randn(4, 6, 768)\n",
    "\n",
    "out = layer(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = nn.TransformerEncoderLayer(768, 12, batch_first=True, dim_feedforward=3072)\n",
    "\n",
    "questions = torch.randn(4, 1, 768)\n",
    "images = torch.randn(4, 6, 768)\n",
    "\n",
    "img_attn = nn.MultiheadAttention(768, 12, batch_first=True)\n",
    "\n",
    "_, attn_scores = img_attn(questions, images, images)\n",
    "\n",
    "out = layer(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 768])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=768, nhead=12, batch_first=True)\n",
    "questions = torch.randn(4, 1, 768)\n",
    "images = torch.randn(4, 6, 768)\n",
    "\n",
    "out = decoder_layer(questions, images)\n",
    "out2 = decoder_layer(images, questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8202e-01, -4.3938e-01,  5.2543e-01,  1.3738e+00,  1.3679e+00,\n",
       "          1.3698e+00,  1.6462e+00,  3.5957e-01, -1.0734e+00,  1.0604e+00,\n",
       "          1.4331e-01,  7.0762e-01, -2.4905e-01, -1.6860e+00,  7.7606e-01,\n",
       "         -4.8757e-01, -1.0267e+00,  1.4065e+00,  1.4866e-01, -8.0037e-01,\n",
       "          1.6971e+00, -4.9145e-01,  6.6795e-01,  4.9078e-01,  5.7478e-02,\n",
       "          4.1770e-01,  1.1652e+00,  1.3306e+00, -1.7638e+00,  2.7130e-01,\n",
       "          1.8238e+00, -1.3587e+00, -7.1948e-01,  2.6626e-01,  1.2651e+00,\n",
       "         -1.0523e+00,  1.3528e+00,  4.7452e-01, -3.1470e-02,  1.4822e+00,\n",
       "          4.2859e-01,  7.7379e-01,  3.6558e-01,  7.0166e-01, -1.0859e+00,\n",
       "          1.6979e+00, -2.1000e-01, -1.0874e+00, -1.4302e+00,  4.2423e-01,\n",
       "         -2.3164e-01,  1.4025e+00, -1.2105e+00,  1.8429e+00, -5.3007e-01,\n",
       "          1.7268e+00,  5.8075e-01,  1.9058e-02,  3.9585e-01,  1.2251e+00,\n",
       "         -7.9854e-01,  4.8526e-01, -2.8563e-02,  1.4292e+00,  2.6455e-01,\n",
       "         -8.8936e-01, -7.0890e-01, -1.2629e+00, -1.6425e+00,  8.9717e-01,\n",
       "          1.2416e+00,  9.4592e-01,  1.3342e-01, -1.2666e+00, -6.5704e-02,\n",
       "         -5.7233e-01, -6.6609e-01, -2.3723e-02,  1.5395e+00,  1.6272e-01,\n",
       "          1.0092e+00, -3.3384e-01,  4.4883e-01,  2.4864e+00, -6.7628e-01,\n",
       "         -8.2845e-01,  7.1783e-01, -9.2820e-01, -2.9796e-01, -1.5001e+00,\n",
       "         -1.1724e+00, -8.1531e-01, -6.9492e-01, -1.2149e+00, -2.2255e+00,\n",
       "          7.5958e-01, -2.2687e+00, -1.3129e+00,  6.1454e-01, -8.2862e-01,\n",
       "         -2.3632e+00, -2.4430e-01,  9.7044e-02, -4.1856e-01,  3.4798e-01,\n",
       "         -1.2963e+00,  1.7159e+00, -4.5631e-01, -8.3319e-01,  3.8274e-01,\n",
       "          1.1720e+00, -1.5587e+00, -2.5589e+00,  9.5821e-01, -4.6892e-01,\n",
       "         -1.1180e+00,  1.4047e+00, -1.2117e+00,  1.3273e-01, -1.9783e-01,\n",
       "         -2.0307e-01,  1.5890e+00, -1.4974e+00,  2.9977e-01, -4.8721e-01,\n",
       "          4.8026e-01, -2.4996e+00, -6.6388e-01,  2.0133e-01, -4.2088e-01,\n",
       "         -1.3558e-01,  3.0175e+00, -1.9784e+00,  1.2572e+00,  7.0652e-02,\n",
       "         -1.0426e+00,  1.2296e+00,  1.3719e+00, -4.4460e-01, -1.9170e-01,\n",
       "          1.3157e+00, -5.9806e-03, -9.0766e-01, -9.8050e-01, -1.4351e-01,\n",
       "         -2.6008e-01,  2.0792e+00,  9.5453e-01, -8.3961e-01, -2.1611e+00,\n",
       "          5.9868e-01, -1.7003e+00, -1.7475e+00,  1.9166e+00, -6.8654e-01,\n",
       "          2.1341e-01,  1.7370e-01,  8.8250e-01, -1.6987e-01, -1.3181e+00,\n",
       "         -9.0580e-01, -1.6074e+00, -9.1426e-01,  3.7041e-01,  8.2235e-01,\n",
       "          5.0078e-01,  4.2919e-01, -8.3313e-01, -1.0416e+00,  3.9493e-01,\n",
       "         -1.4952e-01,  1.4999e+00,  1.1357e+00,  5.0672e-01,  2.0053e+00,\n",
       "          8.0809e-01, -4.3533e-01, -8.8769e-02, -6.6196e-01, -3.8928e-01,\n",
       "         -9.5396e-01,  3.8764e-01, -1.1737e+00, -3.1213e-01,  1.4597e+00,\n",
       "         -1.4798e+00,  2.5232e-01,  5.6688e-01,  1.5194e+00,  9.0687e-01,\n",
       "         -2.7617e-01,  5.2577e-01,  1.2230e+00, -4.9825e-01, -2.1999e-01,\n",
       "         -1.1876e+00, -1.0893e-01, -1.5824e+00, -8.1249e-01,  7.9981e-01,\n",
       "          8.4103e-01, -2.1370e-01,  7.8514e-01,  4.5667e-01,  7.5723e-02,\n",
       "          1.6276e+00,  5.6273e-01,  2.7560e-01,  1.5144e+00, -1.2225e+00,\n",
       "          1.5163e-01,  4.4259e-01, -1.0977e+00,  8.9434e-02,  1.0351e-01,\n",
       "         -4.4832e-01,  1.0521e+00,  7.5605e-01,  3.1664e-01,  6.3247e-01,\n",
       "          7.1927e-01,  1.9984e-01,  4.1546e-01, -7.4383e-01,  7.1270e-02,\n",
       "         -9.7395e-01, -1.3793e-01, -2.5552e+00, -1.3723e+00,  1.0158e+00,\n",
       "         -8.4556e-01, -3.4963e-01,  4.1280e-01, -2.3278e-01, -5.6866e-02,\n",
       "         -6.7933e-01, -6.9341e-01,  4.2200e-01, -5.5357e-01, -3.2828e-01,\n",
       "          1.1595e+00, -4.6757e-01, -4.1217e-01,  8.8727e-01, -9.8192e-01,\n",
       "          7.2410e-01, -6.8965e-02,  7.2193e-01,  2.0858e-01,  1.8810e-01,\n",
       "          1.2296e+00, -8.5935e-01, -1.8682e+00, -8.2468e-01, -1.2461e+00,\n",
       "          6.9371e-02,  1.2710e+00, -8.8318e-01, -4.1724e-02, -7.7705e-01,\n",
       "         -4.8987e-01, -1.0314e+00,  3.8709e-01,  2.8130e-01,  1.4405e-02,\n",
       "         -1.9980e+00, -2.0412e+00, -2.1742e+00, -1.4232e-01, -6.1508e-01,\n",
       "          9.9514e-02,  8.2638e-01, -5.8896e-01, -3.3268e-01, -3.1976e-01,\n",
       "         -1.9090e+00,  1.0390e-01,  3.1092e-01, -5.4981e-01, -9.2855e-01,\n",
       "          1.1681e+00, -1.4659e+00,  1.1857e+00,  5.3164e-01,  4.2604e-01,\n",
       "         -9.7734e-01, -1.0078e+00,  3.1267e-02, -3.9864e-01,  1.1634e+00,\n",
       "         -2.2428e+00,  5.8035e-01,  6.9146e-01, -6.9505e-01, -7.0012e-03,\n",
       "          6.8453e-01,  1.3181e+00, -7.3691e-01, -1.7210e-01,  8.0081e-01,\n",
       "         -1.6172e+00,  5.9137e-01,  1.3154e+00, -1.5215e+00,  7.6472e-02,\n",
       "          7.5496e-01, -1.9950e+00,  4.4344e-01, -8.1633e-01,  8.9441e-01,\n",
       "          5.5143e-01,  4.4012e-01,  7.8140e-01,  5.6521e-01,  9.1070e-01,\n",
       "          4.0802e-01, -1.0487e+00, -5.1603e-01, -8.9328e-01, -7.5306e-01,\n",
       "         -3.8229e-01,  7.5477e-01, -1.2659e+00, -1.2237e+00, -6.3970e-01,\n",
       "          2.4999e-01, -5.4366e-01,  1.8549e-01, -1.2242e-01,  8.3572e-01,\n",
       "         -2.4061e-01, -5.7104e-01, -5.1857e-01,  6.3030e-01, -6.7797e-01,\n",
       "         -3.4210e-02,  4.1788e-01, -1.3949e+00,  4.2919e-01, -2.1888e-01,\n",
       "         -6.3703e-01,  2.7467e-01,  3.2629e-01,  1.7294e+00,  1.1259e+00,\n",
       "          2.4421e-01,  9.1602e-01, -4.7082e-01, -2.9305e-01,  1.1068e+00,\n",
       "         -6.3853e-02, -8.4301e-01, -9.3328e-01, -3.7980e-01,  3.2419e-01,\n",
       "          8.7893e-02, -5.6511e-01,  7.5393e-01, -3.9176e-01,  1.3798e-01,\n",
       "         -4.2102e-01, -1.7330e+00,  1.5882e+00,  7.6790e-02,  1.6082e-01,\n",
       "         -1.4616e-01, -4.1422e-02,  4.4837e-01,  1.1192e+00, -6.3725e-01,\n",
       "         -8.8804e-01, -2.1776e-01, -5.5281e-01, -7.0413e-02,  1.0734e+00,\n",
       "          3.7358e-01,  6.6693e-01,  1.4010e+00, -1.1949e+00,  1.3380e+00,\n",
       "          3.9778e-01, -1.7397e-02, -9.5393e-01, -1.3439e+00,  7.8001e-01,\n",
       "          3.8868e-01,  6.8396e-01, -1.3936e+00,  5.6166e-01,  7.8165e-02,\n",
       "         -3.0224e-01, -4.7130e-01,  1.0984e+00,  1.3117e+00,  1.2308e+00,\n",
       "          4.1759e-01, -8.7690e-01,  3.2572e-01, -8.4743e-01, -4.6683e-01,\n",
       "          8.0113e-01,  2.9775e-02, -1.8374e-02,  3.9902e-01,  5.0104e-01,\n",
       "         -2.3609e-01,  1.2509e+00,  1.0116e+00, -1.5051e-01,  4.2019e-01,\n",
       "         -1.5820e-01,  6.6628e-01, -6.8873e-01, -8.2119e-01, -2.6761e-01,\n",
       "         -1.3109e+00,  1.2692e+00, -1.2540e+00,  1.8713e+00, -2.4843e-01,\n",
       "         -1.5142e+00, -7.5936e-03, -2.0829e-01,  4.1465e-01,  6.3166e-03,\n",
       "          1.2937e+00, -1.7332e+00, -8.7280e-02, -6.2800e-01,  7.2369e-01,\n",
       "          3.0794e-01, -1.2916e+00, -1.6037e+00,  2.0909e-01, -1.6314e+00,\n",
       "          1.7864e-01,  1.4573e-01, -1.1664e+00, -1.2186e+00,  3.1344e-01,\n",
       "          1.6996e+00,  2.8237e+00,  1.5609e+00,  5.4430e-01,  2.0340e-01,\n",
       "          9.1325e-01, -1.0184e+00, -5.5702e-01,  3.0946e-01, -5.6159e-01,\n",
       "          7.2387e-01, -4.8611e-01,  1.3251e+00, -6.4784e-01,  8.5206e-02,\n",
       "          1.0901e-01, -1.8692e-01,  1.3667e+00, -2.0820e+00,  5.2246e-01,\n",
       "          5.4183e-02,  9.2137e-01, -1.3381e+00, -4.5335e-01,  1.3169e+00,\n",
       "          3.1986e-01, -1.4917e+00, -7.0627e-01,  3.3689e-02,  1.8495e+00,\n",
       "         -2.0495e-01,  1.1241e+00, -4.4774e-01,  1.1299e+00, -3.8504e-01,\n",
       "         -7.4032e-02,  4.1134e+00,  6.5898e-01, -1.3670e-01, -3.8665e-01,\n",
       "         -1.1643e+00, -1.0288e+00, -1.1625e+00,  3.1369e-03,  1.0498e+00,\n",
       "          6.1682e-01, -2.5850e-01,  1.1029e-01, -9.0890e-01, -1.0563e-01,\n",
       "         -1.5091e+00, -6.9185e-01, -7.9141e-01, -6.7864e-01, -7.0287e-02,\n",
       "         -1.6278e+00,  1.5341e+00, -9.8298e-01, -7.3200e-01, -9.2711e-01,\n",
       "          1.5416e+00,  2.0798e-01,  1.6595e-02, -3.4225e-01, -2.1137e-02,\n",
       "          4.8129e-01, -5.9291e-01,  2.0419e+00, -5.2842e-01, -3.4547e-01,\n",
       "          1.3371e+00, -7.6388e-01, -1.5360e+00,  1.0547e-01, -1.4324e+00,\n",
       "          1.1286e+00, -6.6237e-01,  7.9608e-01, -9.7018e-01,  9.8366e-01,\n",
       "          2.6439e+00, -6.0243e-01,  1.5672e-01, -2.0832e+00,  2.8474e-01,\n",
       "         -3.0706e+00, -7.3575e-01,  6.5288e-01, -6.8555e-01, -5.5452e-01,\n",
       "          1.1634e+00,  2.4746e-01, -1.7430e+00, -1.0870e+00, -1.7014e-01,\n",
       "         -7.3050e-01,  1.2441e-01,  2.2060e+00, -2.2471e-01,  1.0352e+00,\n",
       "         -6.7461e-01,  2.3554e-01,  8.1709e-02, -7.2113e-02, -1.5179e-01,\n",
       "          6.1296e-01,  2.5794e-01,  2.0822e+00,  1.2097e+00,  2.3366e+00,\n",
       "         -1.1604e+00,  1.2546e+00, -1.5486e+00,  8.7350e-01,  7.7553e-02,\n",
       "         -3.3738e-01,  6.4977e-03,  2.7432e-01, -7.1561e-01,  9.0388e-02,\n",
       "         -1.4512e+00,  7.3020e-01,  3.6861e-01,  1.5772e-01,  6.4296e-01,\n",
       "         -1.4329e+00, -1.0396e+00,  5.3576e-01, -1.4235e-01,  1.0201e+00,\n",
       "          6.4749e-01, -2.0013e-01,  8.1562e-01,  2.6666e-01,  5.9040e-02,\n",
       "          2.0857e-01,  2.7125e-01, -2.0882e+00, -6.9876e-01,  5.4748e-01,\n",
       "         -1.1760e+00, -3.7603e-01, -1.5137e+00, -5.0274e-01,  8.1275e-01,\n",
       "         -9.7251e-01,  1.3579e-01,  3.9424e-01,  8.5324e-02,  1.0610e+00,\n",
       "          7.2466e-01,  1.8664e+00,  8.3336e-01,  1.3222e+00,  9.4079e-01,\n",
       "         -5.4780e-02,  3.1234e-01, -1.0699e+00, -2.2452e-02,  7.0454e-02,\n",
       "          4.0979e-01, -3.8132e-01, -6.5874e-01, -2.0651e-01, -1.7805e+00,\n",
       "          1.0211e+00, -1.6391e+00,  2.2013e-01, -4.7172e-01,  4.4953e-01,\n",
       "         -4.2398e-03,  5.8324e-01,  5.6545e-01,  2.7314e-01,  6.5290e-01,\n",
       "          1.6312e+00,  5.2462e-01, -1.5531e+00, -5.3376e-01,  1.7208e+00,\n",
       "          1.9194e-01, -8.8600e-01, -1.1244e+00, -1.3577e+00,  8.6886e-01,\n",
       "         -9.4505e-02, -1.3768e+00,  3.0020e-01, -4.3997e-01, -2.6154e-01,\n",
       "          1.1191e+00,  1.5720e+00,  3.7092e-01,  1.9515e-01, -1.1426e+00,\n",
       "         -8.9582e-01,  8.4162e-01, -1.5066e-01,  5.0390e-01,  3.4208e-01,\n",
       "         -9.1033e-01, -2.3659e+00,  1.2081e+00,  3.0094e-01,  3.7671e-01,\n",
       "         -2.3014e-01,  3.8265e-01,  1.0597e+00, -3.6717e-01, -3.1924e-01,\n",
       "         -2.1431e+00, -1.0112e+00, -1.0278e+00,  1.5781e+00, -5.0289e-01,\n",
       "          1.0159e+00,  2.2731e-01,  2.7774e-01, -8.3612e-02, -4.8335e-01,\n",
       "          3.4081e-01, -1.3889e+00, -1.8340e+00, -1.6745e-01,  1.6740e-01,\n",
       "          5.5600e-01, -1.5845e+00, -8.3303e-01, -5.6178e-01,  1.6018e+00,\n",
       "          9.0772e-02,  5.2807e-01, -7.2916e-02, -1.0321e+00,  1.6403e+00,\n",
       "         -3.8836e-01, -5.1514e-01,  3.4626e-01,  7.3180e-01, -1.0103e+00,\n",
       "          2.5527e+00, -8.2975e-01,  1.2513e+00,  8.0253e-01,  5.7692e-01,\n",
       "         -4.6727e-01,  7.7546e-01,  6.7412e-01, -1.7802e+00, -7.8815e-01,\n",
       "         -8.3957e-01,  1.0059e-01,  3.0107e-01, -7.5200e-01,  2.4246e-01,\n",
       "         -1.7162e-01, -1.4841e+00, -3.9865e-01,  1.2332e+00,  2.0319e+00,\n",
       "          9.3735e-01,  7.9694e-01, -2.6022e-01, -2.9021e-01,  1.5670e+00,\n",
       "          4.3552e-01,  7.4467e-01, -2.1861e-01, -1.4830e+00,  1.3925e+00,\n",
       "          1.4175e-02,  8.8952e-01,  2.9509e-01, -7.8029e-01,  2.0286e-01,\n",
       "          1.1955e+00,  9.2498e-01, -1.5620e+00, -1.3881e+00, -1.4710e+00,\n",
       "         -1.9637e+00, -2.2735e-01, -9.1476e-01, -3.3666e-02,  1.4867e+00,\n",
       "          6.3159e-01, -6.1429e-01,  7.9198e-01,  1.1037e+00,  5.0524e-01,\n",
       "         -1.1156e+00,  1.6475e+00, -6.0953e-01,  9.1669e-01,  5.4672e-01,\n",
       "         -9.7450e-02,  1.2689e+00,  2.2294e-02, -1.5734e+00,  2.8382e+00,\n",
       "          1.3022e+00,  5.1350e-01, -6.8163e-01,  2.4180e-01, -1.4943e+00,\n",
       "         -5.5358e-01,  2.4990e-01,  2.3020e+00,  9.0373e-01, -8.9180e-01,\n",
       "         -1.3561e+00, -1.0715e+00, -2.5411e+00,  1.3381e+00,  7.3200e-01,\n",
       "         -4.6286e-01, -8.6457e-01,  3.3606e-01, -7.9002e-01,  2.0744e+00,\n",
       "          1.0928e+00,  3.5105e-01,  1.0112e+00,  1.3545e+00,  1.3263e+00,\n",
       "          2.6794e-01, -2.5892e-01,  1.4320e+00]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step(model, loader, acc_fn, answ_len):\n",
    "    \"\"\"\n",
    "    A function that validates the model by going through all the mini-batches in the validation dataloader once.\n",
    "    \"\"\"\n",
    "    print(\"\\tValidating...\")\n",
    "    model.eval()\n",
    "    losses = []  # to save the loss of each mini-batch in order to take their average at the end\n",
    "    accuracies = []  # to save the accuracy of each mini-batch in order to take their average at the end\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (X, y) in enumerate(loader):\n",
    "            outputs = model(**X, labels=y)\n",
    "            loss = outputs.loss\n",
    "            pred = max_to_one_hot(outputs.logits)\n",
    "            acc = acc_fn(pred, y, answ_len)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            accuracies.append(acc)\n",
    "\n",
    "    avg_loss = sum(losses) / len(loader)\n",
    "    avg_acc = sum(accuracies) / len(loader)\n",
    "    \n",
    "    return avg_loss, avg_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikostheodoridis/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = MultiviewViltForQuestionAnswering(6, 210, 768, True, False, False).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.classifier = nn.Sequential(\n",
    "        nn.Linear(768, 1536),\n",
    "        nn.LayerNorm(1536),\n",
    "        nn.GELU(),\n",
    "        nn.Linear(1536, 429)\n",
    "    ).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model.load_state_dict(torch.load(\"/home/nikostheodoridis/Trained Models/2024-07-08 00:07:49/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p1, p2 in zip(model.parameters(), trained_model.parameters()):\n",
    "#     assert torch.equal(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = ISVQA(qa_path=\"/home/nikostheodoridis/isvqa/val_set.json\",\n",
    "                nuscenes_path=\"/home/nikostheodoridis/nuscenes/samples\",\n",
    "                answers_path=\"/home/nikostheodoridis/isvqa/answers.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(val_set, batch_size=6, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = []\n",
    "# untrained_predictions = []\n",
    "# trained_predictions = []\n",
    "\n",
    "# model.eval()\n",
    "# trained_model.eval()\n",
    "# for i in range(2576):\n",
    "#     inputs, target = val_set[i]\n",
    "\n",
    "#     targets.append(target)\n",
    "\n",
    "#     with torch.inference_mode():\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions: torch.Tensor, targets: torch.Tensor, answers_len: int) -> float:\n",
    "    cnt = torch.eq(torch.eq(predictions, targets).sum(dim=1), answers_len).sum()\n",
    "    return cnt.item() / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidating...\n"
     ]
    }
   ],
   "source": [
    "untrained_loss, untrained_acc = val_step(model, val_loader, accuracy, 429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tValidating...\n"
     ]
    }
   ],
   "source": [
    "trained_loss, trained_acc = val_step(trained_model, val_loader, accuracy, 429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303.8099614342978\n",
      "0.0011627906976744186\n"
     ]
    }
   ],
   "source": [
    "print(untrained_loss)\n",
    "print(untrained_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5099486532945967\n",
      "0.6003875968992246\n"
     ]
    }
   ],
   "source": [
    "print(trained_loss)\n",
    "print(trained_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/nikostheodoridis/isvqa/answers_counter.json\") as f:\n",
    "    answers_cnt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'yes': 13564,\n",
       "         'no': 3734,\n",
       "         'one': 3663,\n",
       "         'white': 2893,\n",
       "         'two': 2544,\n",
       "         'red': 1205,\n",
       "         'black': 1046,\n",
       "         'blue': 1025,\n",
       "         'three': 986,\n",
       "         'green': 968,\n",
       "         'yellow': 930,\n",
       "         'orange': 782,\n",
       "         'four': 529,\n",
       "         'night': 464,\n",
       "         'rainy': 434,\n",
       "         'gray': 365,\n",
       "         'black and white': 345,\n",
       "         'silver': 287,\n",
       "         'zero': 254,\n",
       "         'five': 218,\n",
       "         'orange and white': 178,\n",
       "         'six': 156,\n",
       "         'left': 151,\n",
       "         'none': 147,\n",
       "         'ahead': 147,\n",
       "         'right': 141,\n",
       "         'fedex': 136,\n",
       "         'brown': 134,\n",
       "         'cloudy': 129,\n",
       "         'slow': 119,\n",
       "         'ups': 114,\n",
       "         'bus': 112,\n",
       "         'raining': 111,\n",
       "         'wet': 111,\n",
       "         'sunny': 107,\n",
       "         'ryder': 95,\n",
       "         'urban': 93,\n",
       "         'twenty-three': 92,\n",
       "         'stop': 89,\n",
       "         'day': 77,\n",
       "         'hump': 69,\n",
       "         'brick': 69,\n",
       "         'red and white': 57,\n",
       "         'twenty-five': 55,\n",
       "         'bridge': 55,\n",
       "         'rectangle': 54,\n",
       "         'trees': 53,\n",
       "         'truck': 52,\n",
       "         'city': 51,\n",
       "         'toyota': 50,\n",
       "         'nineteen': 48,\n",
       "         'on': 46,\n",
       "         'rain': 40,\n",
       "         'seven': 39,\n",
       "         'forty': 37,\n",
       "         'french': 36,\n",
       "         'black and yellow': 36,\n",
       "         'innosparks': 35,\n",
       "         'square': 34,\n",
       "         'ford': 34,\n",
       "         'blue and green': 34,\n",
       "         'umbrella': 33,\n",
       "         'night time': 33,\n",
       "         'metal': 32,\n",
       "         'arrow': 32,\n",
       "         'van': 31,\n",
       "         'motorcycle': 29,\n",
       "         'parked': 29,\n",
       "         'fence': 29,\n",
       "         'construction': 28,\n",
       "         'nighttime': 28,\n",
       "         'p': 28,\n",
       "         'eversource energy': 28,\n",
       "         'green and blue': 28,\n",
       "         'nuss': 27,\n",
       "         'car': 27,\n",
       "         'crosswalk': 27,\n",
       "         'boston': 26,\n",
       "         'dark': 26,\n",
       "         'one way': 26,\n",
       "         'cars': 25,\n",
       "         'tree': 25,\n",
       "         'yankee': 25,\n",
       "         'do not enter': 25,\n",
       "         'water': 25,\n",
       "         'building': 25,\n",
       "         'twelve': 24,\n",
       "         'twenty-one': 24,\n",
       "         'pink': 24,\n",
       "         'suv': 23,\n",
       "         'starbucks': 23,\n",
       "         'north coast': 23,\n",
       "         'bicycle': 23,\n",
       "         'blue and white': 23,\n",
       "         'john nagle': 23,\n",
       "         'hump ahead': 22,\n",
       "         'eight': 22,\n",
       "         'behind': 22,\n",
       "         'bike': 21,\n",
       "         'xfinity': 21,\n",
       "         'sidewalk': 21,\n",
       "         'm': 20,\n",
       "         'harbor place': 20,\n",
       "         'usps': 20,\n",
       "         'both': 20,\n",
       "         'round': 20,\n",
       "         'parking lot': 20,\n",
       "         'white and orange': 19,\n",
       "         'orange and gray': 19,\n",
       "         'only': 19,\n",
       "         'stop sign': 19,\n",
       "         'ninety': 19,\n",
       "         'chain link': 19,\n",
       "         'penske': 19,\n",
       "         'fusionopolis two': 19,\n",
       "         'jeep': 18,\n",
       "         'holland ave': 18,\n",
       "         'gemalto': 18,\n",
       "         'white and yellow': 18,\n",
       "         'concrete': 18,\n",
       "         'hood': 18,\n",
       "         'circle': 17,\n",
       "         'gray and orange': 17,\n",
       "         'solid': 17,\n",
       "         'river': 17,\n",
       "         'synthesis': 17,\n",
       "         'backpack': 17,\n",
       "         'nine': 16,\n",
       "         'row thirty-four': 16,\n",
       "         'grass': 16,\n",
       "         'sportello': 16,\n",
       "         'yellow and black': 16,\n",
       "         'starbucks coffee': 16,\n",
       "         'dhl': 16,\n",
       "         'residential': 16,\n",
       "         'v': 16,\n",
       "         'caution': 15,\n",
       "         'one north gateway': 15,\n",
       "         'back right': 15,\n",
       "         'dog': 15,\n",
       "         'clouds': 15,\n",
       "         'crane': 15,\n",
       "         'nucleos': 15,\n",
       "         'bus stop': 14,\n",
       "         'closed': 14,\n",
       "         'nine hundred and seventy': 14,\n",
       "         'fire hydrant': 14,\n",
       "         'one north link': 14,\n",
       "         'open': 14,\n",
       "         'harvey': 13,\n",
       "         'glass': 13,\n",
       "         'bricks': 13,\n",
       "         'worldwide services': 13,\n",
       "         'speedpost': 12,\n",
       "         'walking': 12,\n",
       "         'road': 12,\n",
       "         'wheelchair': 12,\n",
       "         'museum': 12,\n",
       "         'seventy-five': 12,\n",
       "         'more': 12,\n",
       "         'innovationsquareboston': 12,\n",
       "         'yankee lobster': 12,\n",
       "         'sedan': 11,\n",
       "         'rectangular': 11,\n",
       "         'yellow and white': 11,\n",
       "         'x ing': 11,\n",
       "         'harpoon brewery': 11,\n",
       "         'evening': 11,\n",
       "         'canteen': 11,\n",
       "         'business link': 11,\n",
       "         'down': 11,\n",
       "         'ladder': 10,\n",
       "         'front': 10,\n",
       "         'ten': 10,\n",
       "         'wood': 10,\n",
       "         'msc': 10,\n",
       "         'overcast': 10,\n",
       "         'barbed wire': 10,\n",
       "         'two way': 10,\n",
       "         'shorts': 10,\n",
       "         'woman': 10,\n",
       "         'cat': 9,\n",
       "         'three way': 9,\n",
       "         'sysco': 9,\n",
       "         'centros': 9,\n",
       "         'light': 9,\n",
       "         'parking garage': 9,\n",
       "         'x': 9,\n",
       "         'empty': 9,\n",
       "         'works ahead': 9,\n",
       "         'ninety-three': 9,\n",
       "         'mercedes': 9,\n",
       "         'diamond': 9,\n",
       "         'biopolis dr': 9,\n",
       "         'front left': 9,\n",
       "         'cones': 9,\n",
       "         'commercial': 9,\n",
       "         'dunkin donuts': 9,\n",
       "         'seafood': 9,\n",
       "         'suffolk': 9,\n",
       "         's': 9,\n",
       "         'skanska': 9,\n",
       "         '': 8,\n",
       "         'mass bay credit union': 8,\n",
       "         'one hundred and fifty-one': 8,\n",
       "         'triangle': 8,\n",
       "         'four hundred and fifty-one': 8,\n",
       "         'five eleven': 8,\n",
       "         'macco energy': 8,\n",
       "         'mail truck': 8,\n",
       "         'back': 8,\n",
       "         'honda': 8,\n",
       "         'helmet': 8,\n",
       "         'nus': 8,\n",
       "         'double': 8,\n",
       "         'industrial': 8,\n",
       "         'squares': 8,\n",
       "         'bag': 8,\n",
       "         'taxi': 8,\n",
       "         'stopped': 7,\n",
       "         'four way': 7,\n",
       "         'whiskey priest': 7,\n",
       "         'traffic lights': 7,\n",
       "         'go': 7,\n",
       "         'morning': 7,\n",
       "         'usa': 7,\n",
       "         'reduce speed now': 7,\n",
       "         'dry': 7,\n",
       "         'green and white': 7,\n",
       "         'gold': 7,\n",
       "         'bicycles': 7,\n",
       "         'we deliver for you': 7,\n",
       "         'eleven': 7,\n",
       "         'bench': 7,\n",
       "         'innovation and design': 7,\n",
       "         'legal': 7,\n",
       "         'la casa de pedro': 7,\n",
       "         'sandcrawler': 7,\n",
       "         'traffic cones': 7,\n",
       "         'fort point market': 7,\n",
       "         'exit only': 7,\n",
       "         'red and gray': 7,\n",
       "         'vpne': 7,\n",
       "         'autodesk': 6,\n",
       "         'scooter': 6,\n",
       "         'rounded': 6,\n",
       "         'brown and white': 6,\n",
       "         'stars ave': 6,\n",
       "         'female': 6,\n",
       "         'enterprise': 6,\n",
       "         'twenty-two': 6,\n",
       "         'orange and black': 6,\n",
       "         'forward': 6,\n",
       "         'white and black': 6,\n",
       "         'male': 6,\n",
       "         \"don't walk\": 6,\n",
       "         'bmw': 6,\n",
       "         'red light': 6,\n",
       "         'blue harvest': 6,\n",
       "         'plants': 6,\n",
       "         'to right': 6,\n",
       "         'dashed': 6,\n",
       "         'red and blue': 6,\n",
       "         'available liftgate service': 6,\n",
       "         'www': 6,\n",
       "         'away': 6,\n",
       "         'boston freight terminals': 6,\n",
       "         'parking': 6,\n",
       "         'flett': 6,\n",
       "         'rosa mexicano': 5,\n",
       "         'on sidewalk': 5,\n",
       "         'back left': 5,\n",
       "         'cone': 5,\n",
       "         'isuzu': 5,\n",
       "         'windows': 5,\n",
       "         'sbwtc': 5,\n",
       "         'lights': 5,\n",
       "         'american': 5,\n",
       "         'portsdown rd': 5,\n",
       "         'e': 5,\n",
       "         'man': 5,\n",
       "         'true': 5,\n",
       "         'dark blue': 5,\n",
       "         'flowers': 5,\n",
       "         'arch': 5,\n",
       "         'wagamama': 5,\n",
       "         'fifteen': 5,\n",
       "         'curved': 5,\n",
       "         'kent ridge drive': 5,\n",
       "         'd': 5,\n",
       "         '4x4': 5,\n",
       "         'clear': 5,\n",
       "         'railroad crossing': 5,\n",
       "         'moving': 5,\n",
       "         'ayer rajah': 5,\n",
       "         'sitting': 5,\n",
       "         'phone': 5,\n",
       "         'salmon': 5,\n",
       "         'parking meter': 5,\n",
       "         'person': 5,\n",
       "         'straight': 5,\n",
       "         'xpo': 5,\n",
       "         'supercamp': 5,\n",
       "         'minivan': 5,\n",
       "         'tcoms': 5,\n",
       "         'factory outlet': 5,\n",
       "         'english': 5,\n",
       "         'palm tree': 5,\n",
       "         'mediapolis': 5,\n",
       "         'sign': 5,\n",
       "         'audi': 5,\n",
       "         'thirty-six': 5,\n",
       "         'seaport world trade center': 5,\n",
       "         'mail': 5,\n",
       "         'all': 5,\n",
       "         'construction ahead': 4,\n",
       "         'suburban': 4,\n",
       "         'mitsubishi': 4,\n",
       "         'bush': 4,\n",
       "         'sunglasses': 4,\n",
       "         'yang ming': 4,\n",
       "         'blue and yellow': 4,\n",
       "         'mitsubishi electric': 4,\n",
       "         'double decker bus': 4,\n",
       "         'towards': 4,\n",
       "         'up': 4,\n",
       "         'legal harborside': 4,\n",
       "         'lobster': 4,\n",
       "         'fios': 4,\n",
       "         'radius bank': 4,\n",
       "         'standing': 4,\n",
       "         'arrows': 4,\n",
       "         'triangles': 4,\n",
       "         'lexus': 4,\n",
       "         'green and red': 4,\n",
       "         'false': 4,\n",
       "         'nothing': 4,\n",
       "         'pedestrians': 4,\n",
       "         'gateway': 4,\n",
       "         'cranes': 4,\n",
       "         'paul w': 4,\n",
       "         'harpoon': 4,\n",
       "         'smoke shop': 4,\n",
       "         'red and green': 4,\n",
       "         'donuts': 4,\n",
       "         'green and orange': 4,\n",
       "         'jeans': 4,\n",
       "         'blue and orange': 4,\n",
       "         'singapore science park': 4,\n",
       "         'ship': 4,\n",
       "         'alumni house': 4,\n",
       "         'on road': 4,\n",
       "         'stroller': 4,\n",
       "         'exit': 4,\n",
       "         'bushes': 4,\n",
       "         'detour': 4,\n",
       "         'blue harvest fisheries': 4,\n",
       "         'partly cloudy': 4,\n",
       "         'w': 4,\n",
       "         'bank of america': 4,\n",
       "         'white car': 4,\n",
       "         'cell phone': 4,\n",
       "         'innovation': 4,\n",
       "         'mountain': 4,\n",
       "         'excavator': 3,\n",
       "         'yield': 3,\n",
       "         'three hundred': 3,\n",
       "         'thirty-five': 3,\n",
       "         'mazda': 3,\n",
       "         'dusk': 3,\n",
       "         'sun': 3,\n",
       "         'beige': 3,\n",
       "         'crossing street': 3,\n",
       "         'singapore': 3,\n",
       "         'outside': 3,\n",
       "         'bad': 3,\n",
       "         'site access': 3,\n",
       "         'dead end': 3,\n",
       "         'geico': 3,\n",
       "         'four hundred and eleven': 3,\n",
       "         'stairs': 3,\n",
       "         'low': 3,\n",
       "         'h': 3,\n",
       "         'sahara': 3,\n",
       "         'chevy': 3,\n",
       "         'buildings': 3,\n",
       "         'sbs transit': 3,\n",
       "         'six hundred and seventeen five hundred and twenty-three eight thousand': 3,\n",
       "         'fusionopolis': 3,\n",
       "         'traffic light': 3,\n",
       "         'daylight': 3,\n",
       "         'self storage': 3,\n",
       "         'palm trees': 3,\n",
       "         'american flag': 3,\n",
       "         'short': 3,\n",
       "         'seventy-nine': 3,\n",
       "         'biopolis rd': 3,\n",
       "         'street': 3,\n",
       "         'mandm': 3,\n",
       "         'blue dragon': 3,\n",
       "         'humps': 3,\n",
       "         'twenty': 3,\n",
       "         'white and red': 3,\n",
       "         't': 3,\n",
       "         'mailbox': 3,\n",
       "         'peapod': 3,\n",
       "         'congress st': 3,\n",
       "         'future starts here': 3,\n",
       "         'park': 3,\n",
       "         'large': 3,\n",
       "         'construction workers': 3,\n",
       "         'mirror': 3,\n",
       "         'hat': 3,\n",
       "         'twenty-eight': 3,\n",
       "         'foley': 3,\n",
       "         '02148m0003': 3,\n",
       "         'tan': 3,\n",
       "         'synapse': 3,\n",
       "         'business': 3,\n",
       "         'green and yellow': 3,\n",
       "         'pickup truck': 3,\n",
       "         'pandg': 3,\n",
       "         'dark gray': 3,\n",
       "         'intersection': 3,\n",
       "         'public parking': 3,\n",
       "         'for lease': 3,\n",
       "         'striped': 3,\n",
       "         'light blue': 3,\n",
       "         'trucks': 3})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(answers_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Start\n",
    "import json\n",
    "import random\n",
    "train_path = \"/home/nikostheodoridis/nuscenes-qa/train_set.json\"\n",
    "\n",
    "val_path = \"/home/nikostheodoridis/nuscenes-qa/val_set.json\"\n",
    "\n",
    "test_path = \"/home/nikostheodoridis/nuscenes-qa/test_set.json\"\n",
    "with open(train_path) as f:\n",
    "    train_data = json.load(f)\n",
    "\n",
    "with open(val_path) as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "with open(test_path) as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "for data in train_data:\n",
    "    if data in test_data:\n",
    "        print(\"False\")\n",
    "        break\n",
    "else:\n",
    "    print(\"True\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
